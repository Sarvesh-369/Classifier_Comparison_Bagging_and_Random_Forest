{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1695821289676,"user":{"displayName":"Sarvesh B","userId":"06476357870668609742"},"user_tz":-330},"id":"NTMxJEIb0ulI"},"outputs":[],"source":["# Import the libraries\n","from typing import List, Tuple\n","\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"uJjEhA-l0ull"},"source":["## Baseline Model\n","\n","For the baseline model, implement a normal `Decision Tree` classifier"]},{"cell_type":"markdown","metadata":{"id":"txMKZtdS0ulm"},"source":["### Data Proprocessing (if any)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":528,"status":"ok","timestamp":1695823173640,"user":{"displayName":"Sarvesh B","userId":"06476357870668609742"},"user_tz":-330},"id":"mSoI_fbC0ulo","outputId":"69bbae02-e2fb-47c5-c5f3-e361a6438460"},"outputs":[{"data":{"text/plain":["Index(['Party', 'Feature-1', 'Feature-2', 'Feature-3', 'Feature-4',\n","       'Feature-5', 'Feature-6', 'Feature-7', 'Feature-8', 'Feature-9',\n","       'Feature-10', 'Feature-11', 'Feature-12', 'Feature-13', 'Feature-14',\n","       'Feature-15', 'Feature-16'],\n","      dtype='object')"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df_train = pd.read_csv('train.csv')\n","df_val = pd.read_csv('val.csv')\n","df_train.columns"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1695823132767,"user":{"displayName":"Sarvesh B","userId":"06476357870668609742"},"user_tz":-330},"id":"I0x0yXbz0ulq"},"outputs":[],"source":["def preprocess_data(df):\n","    # Convert 'y' and 'n' to binary values (1 and 0)\n","    df = df.replace({'y': 1, 'n': 0})\n","\n","    # Map \"democrat\" to 1 and \"republican\" to 0\n","    df['Party'] = df['Party'].map({'democrat': 0, 'republican': 1})\n","\n","    # Split the data into features and labels\n","    X = df.drop('Party', axis=1).values\n","    y = df['Party'].values\n","\n","    return X, y"]},{"cell_type":"markdown","metadata":{"id":"D9CHV35Y0ulq"},"source":["Implement the Decision Tree class below."]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":573,"status":"ok","timestamp":1695823135654,"user":{"displayName":"Sarvesh B","userId":"06476357870668609742"},"user_tz":-330},"id":"LUpc3nrj0ulr"},"outputs":[],"source":["from collections import Counter\n","class Node:\n","    def __init__(self, feature=None, threshold=None, left=None, right=None,*,value=None):\n","        self.feature = feature\n","        self.threshold = threshold\n","        self.left = left\n","        self.right = right\n","        self.value = value\n","\n","    def is_leaf_node(self):\n","        return self.value is not None\n","\n","\n","class DecisionTree:\n","    def __init__(self, min_samples_split=2, max_depth=100, n_features=None):\n","        self.min_samples_split=min_samples_split\n","        self.max_depth=max_depth\n","        self.n_features=n_features\n","        self.root=None\n","\n","    def fit(self, X, y):\n","        self.n_features = X.shape[1] if not self.n_features else min(X.shape[1],self.n_features)\n","        self.root = self._grow_tree(X, y)\n","\n","    def _grow_tree(self, X, y, depth=0):\n","        n_samples, n_feats = X.shape\n","        n_labels = len(np.unique(y))\n","\n","        # check the stopping criteria\n","        if (depth>=self.max_depth or n_labels==1 or n_samples<self.min_samples_split):\n","            leaf_value = self._most_common_label(y)\n","            return Node(value=leaf_value)\n","\n","        feat_idxs = np.random.choice(n_feats, self.n_features, replace=False)\n","\n","        # find the best split\n","        best_feature, best_thresh = self._best_split(X, y, feat_idxs)\n","\n","        # create child nodes\n","        left_idxs, right_idxs = self._split(X[:, best_feature], best_thresh)\n","        left = self._grow_tree(X[left_idxs, :], y[left_idxs], depth+1)\n","        right = self._grow_tree(X[right_idxs, :], y[right_idxs], depth+1)\n","        return Node(best_feature, best_thresh, left, right)\n","\n","\n","    def _best_split(self, X, y, feat_idxs):\n","        best_gain = -1\n","        split_idx, split_threshold = None, None\n","\n","        for feat_idx in feat_idxs:\n","            X_column = X[:, feat_idx]\n","            thresholds = np.unique(X_column)\n","\n","            for thr in thresholds:\n","                # calculate the information gain\n","                gain = self._information_gain(y, X_column, thr)\n","\n","                if gain > best_gain:\n","                    best_gain = gain\n","                    split_idx = feat_idx\n","                    split_threshold = thr\n","\n","        return split_idx, split_threshold\n","\n","\n","    def _information_gain(self, y, X_column, threshold):\n","        # parent entropy\n","        parent_entropy = self._entropy(y)\n","\n","        # create children\n","        left_idxs, right_idxs = self._split(X_column, threshold)\n","\n","        if len(left_idxs) == 0 or len(right_idxs) == 0:\n","            return 0\n","\n","        # calculate the weighted avg. entropy of children\n","        n = len(y)\n","        n_l, n_r = len(left_idxs), len(right_idxs)\n","        e_l, e_r = self._entropy(y[left_idxs]), self._entropy(y[right_idxs])\n","        child_entropy = (n_l/n) * e_l + (n_r/n) * e_r\n","\n","        # calculate the IG\n","        information_gain = parent_entropy - child_entropy\n","        return information_gain\n","\n","    def _split(self, X_column, split_thresh):\n","        left_idxs = np.argwhere(X_column <= split_thresh).flatten()\n","        right_idxs = np.argwhere(X_column > split_thresh).flatten()\n","        return left_idxs, right_idxs\n","\n","    def _entropy(self, y):\n","        hist = np.bincount(y)\n","        ps = hist / len(y)\n","        return -np.sum([p * np.log(p) for p in ps if p>0])\n","\n","\n","    def _most_common_label(self, y):\n","        counter = Counter(y)\n","        value = counter.most_common(1)[0][0]\n","        return value\n","\n","    def predict(self, X):\n","        return np.array([self._traverse_tree(x, self.root) for x in X])\n","\n","    def _traverse_tree(self, x, node):\n","        if node.is_leaf_node():\n","            return node.value\n","\n","        if x[node.feature] <= node.threshold:\n","            return self._traverse_tree(x, node.left)\n","        return self._traverse_tree(x, node.right)"]},{"cell_type":"markdown","metadata":{"id":"9UhQyZ4d0uls"},"source":["Train the model on the training data and report the accuracy and [F1 score](https://en.wikipedia.org/wiki/F-score) on the validation data."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":528,"status":"ok","timestamp":1695823192681,"user":{"displayName":"Sarvesh B","userId":"06476357870668609742"},"user_tz":-330},"id":"7_lSADM-0ult","outputId":"e337129d-8d4b-41c0-8d18-1ff047a0dcdf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy on validation data: 0.9090909090909091\n","F1 Score on validation data: 0.8799999999999999\n"]}],"source":["X_train, y_train = preprocess_data(df_train)\n","X_val, y_val = preprocess_data(df_val)\n","\n","# Initialize and train the DecisionTree model\n","clf = DecisionTree(max_depth=9)\n","clf.fit(X_train, y_train)\n","predictions = clf.predict(X_val)\n","\n","# Define a function to calculate accuracy\n","def accuracy(y_test, y_pred):\n","    return np.sum(y_test == y_pred) / len(y_test)\n","\n","# Define a function to calculate F1 score\n","def calculate_f1_score(y_true, y_pred):\n","    tp = np.sum((y_true == 1) & (y_pred == 1))\n","    fp = np.sum((y_true == 0) & (y_pred == 1))\n","    fn = np.sum((y_true == 1) & (y_pred == 0))\n","\n","    precision = tp / (tp + fp)\n","    recall = tp / (tp + fn)\n","\n","    f1 = 2 * (precision * recall) / (precision + recall)\n","    return f1\n","\n","# Make predictions on the validation data\n","y_val_pred = clf.predict(X_val)\n","\n","# Calculate accuracy and F1 score\n","accuracy = accuracy(y_val, y_val_pred)\n","f1 = calculate_f1_score(y_val, y_val_pred)\n","\n","print(f\"Accuracy on validation data: {accuracy}\")\n","print(f\"F1 Score on validation data: {f1}\")"]},{"cell_type":"markdown","metadata":{"id":"nDKiduWg0ult"},"source":["## Bagging"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":615,"status":"ok","timestamp":1695824244014,"user":{"displayName":"Sarvesh B","userId":"06476357870668609742"},"user_tz":-330},"id":"6UIXKp8y0ulv"},"outputs":[],"source":["def get_bootstrap_samples(df: pd.DataFrame, n_samples: int, sample_fraction: float, target: str) -> List[pd.DataFrame]:\n","    \"\"\"Generate bootstrap samples using the given dataframe.\n","    \"\"\"\n","    bootstrap_samples = []\n","\n","    for _ in range(n_samples):\n","        # Randomly select row indices with replacement\n","        sample_indices = np.random.choice(df.index, size=int(len(df) * sample_fraction), replace=True)\n","\n","        # Create a bootstrap sample by selecting rows based on the sampled indices, including the target variable\n","        bootstrap_sample = df.loc[sample_indices]\n","\n","        # Append the bootstrap sample to the list\n","        bootstrap_samples.append(bootstrap_sample)\n","\n","    return bootstrap_samples"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":1035,"status":"ok","timestamp":1695824581932,"user":{"displayName":"Sarvesh B","userId":"06476357870668609742"},"user_tz":-330},"id":"-8CP-8hi0ulw"},"outputs":[],"source":["n_trees = 10\n","sample_fraction = 0.8\n","target = 'Party' # TODO: Set the target column\n","trees = []\n","\n","bootstrap_samples = get_bootstrap_samples(df_train, n_trees, sample_fraction, target)\n","\n","# Write your code below\n","for bootstrap_sample in bootstrap_samples:\n","    # Replace 'y' with 1 and 'n' with 0 in both features (X) and target (y)\n","    bootstrap_sample = bootstrap_sample.replace({'y': 1, 'n': 0, 'republican': 1, 'democrat': 0})\n","\n","    # Separate features (X) and target (y)\n","    X = bootstrap_sample.drop(target, axis=1)\n","    y = bootstrap_sample[target]\n","\n","    # Initialize and train a DecisionTree model\n","    tree = DecisionTree(max_depth=5)\n","    tree.fit(X.values, y.values)\n","\n","    # Append the trained tree to the 'trees' list\n","    trees.append(tree)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":633,"status":"ok","timestamp":1695824821870,"user":{"displayName":"Sarvesh B","userId":"06476357870668609742"},"user_tz":-330},"id":"F7-6QWQs0uly","outputId":"4107fe82-fa78-4a8c-8282-f83cc5401876"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.94\n","F1 Score: 0.92\n"]}],"source":["X_val, y_val = preprocess_data(df_val)\n","\n","# Initialize lists to store predictions from each tree\n","all_tree_predictions = []\n","\n","# Make predictions for each data point using each trained tree\n","for tree in trees:\n","    tree_predictions = tree.predict(X_val)\n","    all_tree_predictions.append(tree_predictions)\n","\n","# Combine predictions using majority voting\n","combined_predictions = np.mean(np.array(all_tree_predictions), axis=0) >= 0.5\n","\n","# Calculate accuracy and F1 Score\n","correct_predictions = np.sum(combined_predictions == y_val)\n","total_samples = len(y_val)\n","accuracy = correct_predictions / total_samples\n","\n","# Calculate precision, recall, and F1 Score\n","true_positives = np.sum((combined_predictions == 1) & (y_val == 1))\n","false_positives = np.sum((combined_predictions == 1) & (y_val == 0))\n","false_negatives = np.sum((combined_predictions == 0) & (y_val == 1))\n","\n","precision = true_positives / (true_positives + false_positives)\n","recall = true_positives / (true_positives + false_negatives)\n","\n","# Calculate F1 Score\n","f1_score = 2 * (precision * recall) / (precision + recall)\n","\n","# Print accuracy and F1 Score\n","print(f\"Accuracy: {accuracy:.2f}\")\n","print(f\"F1 Score: {f1_score:.2f}\")"]},{"cell_type":"markdown","metadata":{"id":"ZgViR4Fh0uly"},"source":["## Random Forest Algorithm"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1695824912692,"user":{"displayName":"Sarvesh B","userId":"06476357870668609742"},"user_tz":-330},"id":"aTZ_1ran0ul0"},"outputs":[],"source":["def get_random_forest_bootstrap_samples(df: pd.DataFrame, n_samples: int, sample_fraction: float, feature_fraction: float, target: str) -> Tuple[List[pd.DataFrame], List[str]]:\n","    \"\"\"Generate bootstrap samples using the given dataframe.\n","    \"\"\"\n","    bootstrap_samples = []\n","    selected_features_list = []\n","\n","    for _ in range(n_samples):\n","        # Randomly select row indices with replacement\n","        sample_indices = np.random.choice(df.index, size=int(len(df) * sample_fraction), replace=True)\n","\n","        # Randomly select a subset of features\n","        num_features = int(len(df.columns) * feature_fraction)\n","        selected_features = np.random.choice(df.columns.drop(target), size=num_features, replace=False)\n","        selected_features_list.append(selected_features.tolist())\n","\n","        # Create a bootstrap sample by selecting rows and features based on the sampled indices\n","        bootstrap_sample = df.loc[sample_indices, [target] + selected_features.tolist()]\n","\n","        # Append the bootstrap sample to the list\n","        bootstrap_samples.append(bootstrap_sample)\n","\n","    return bootstrap_samples, selected_features_list"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1695825139402,"user":{"displayName":"Sarvesh B","userId":"06476357870668609742"},"user_tz":-330},"id":"XJ61sc9q0ul1"},"outputs":[],"source":["n_trees = 10\n","sample_fraction = 0.8\n","feature_fraction = 0.7\n","target = 'Party' # TODO: Set the target column\n","trees = []\n","\n","bootstrap_samples, sample_features = get_random_forest_bootstrap_samples(df_train, n_trees, sample_fraction, feature_fraction, target)\n","\n","# Write your code below\n","for bootstrap_sample, selected_features in zip(bootstrap_samples, sample_features):\n","    # Replace 'y' with 1, 'n' with 0, 'republican' with 1, and 'democrat' with 0 in both features (X) and target (y)\n","    bootstrap_sample = bootstrap_sample.replace({'y': 1, 'n': 0, 'republican': 1, 'democrat': 0})\n","\n","    # Separate features (X) and target (y)\n","    X = bootstrap_sample[selected_features]\n","    y = bootstrap_sample[target]\n","\n","    # Initialize and train a DecisionTree model\n","    tree = DecisionTree(min_samples_split=2, max_depth=5, n_features=None)\n","    tree.fit(X.values, y.values)\n","\n","    # Append the trained tree to the 'trees' list\n","    trees.append(tree)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"35iXKlJK0ul5"},"source":["## Prediction on Test Data"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":466,"status":"ok","timestamp":1695825668201,"user":{"displayName":"Sarvesh B","userId":"06476357870668609742"},"user_tz":-330},"id":"w4fOLI8N0ul6"},"outputs":[],"source":["df_test = pd.read_csv('test.csv')"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1695825672174,"user":{"displayName":"Sarvesh B","userId":"06476357870668609742"},"user_tz":-330},"id":"jZ-Cvte06I-q"},"outputs":[],"source":["df_test = df_test.replace({'y': 1, 'n': 0})\n","\n","# Initialize an empty list to store individual Decision Tree predictions\n","individual_predictions = []\n","\n","# Make predictions on the test data using each Decision Tree\n","for tree in trees:\n","    X_test = df_test[sample_features[0]]  # Use the same selected features as the training data\n","    tree_predictions = tree.predict(X_test.values)\n","    individual_predictions.append(tree_predictions)\n","\n","# Combine predictions using majority voting\n","combined_predictions = np.mean(np.array(individual_predictions), axis=0) >= 0.5\n","\n","# Create a DataFrame with 'ID' and 'Party' columns\n","submission_df = pd.DataFrame({'ID': df_test['ID'], 'Party': combined_predictions.astype(int)})\n","\n","# Save the predictions to a CSV file\n","submission_df.to_csv('submission.csv', index=False)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
